**Warnings and Cautions:**
- Emphasize the critical importance of avoiding plagiarism and ensuring the originality of the content generated by the AI.

I would like to request a rewrite of Chapter 2 with proper references. Specifically, I need the following:

- Compile a comprehensive list of all sources cited in the thesis, formatted according to IEEE guidelines. Ensure:
  - All in-text citations are included in the reference list.
  - No references are listed that were not cited in the text.
  - Correct and consistent formatting for each reference type (journal articles, books, websites, etc.).
  - References should be listed with numbers [11], [12], etc and started number from [11].
  - When writing the chapter, reference numbers should be included in the text like [11], [12].
  - The number of references must not exceed ten
  - Put your final answer in the md file

Please ensure the highest level of accuracy and adherence to IEEE formatting standards.



## Chapter 2: Data Collection 

### 2.1 Data Sources

The primary data source for this study is the X (formerly Twitter) platform. X is a widely used social media platform that allows users to share short messages, known as tweets, with their followers and the public. The platform has a vast user base spanning various geographical regions, making it an ideal source for collecting global opinions and sentiments. The data collected from X will consist of tweets related to the Saudi Horse Cup. These tweets will be identified using relevant keywords, hashtags, and mentions associated with the event. The specific keywords and hashtags will be determined based on a thorough analysis of the event's official promotions, media coverage, and user-generated content. In addition to the text content of the tweets, we will also collect metadata associated with each tweet, such as the timestamp, user location (if available), language, and user profile information. This metadata will be crucial for conducting geographical analysis and understanding the demographics of the users expressing their opinions. To ensure the comprehensiveness and reliability of the data, we will focus on collecting tweets from a specified time period surrounding the Saudi Horse Cup event. This time period will include the lead-up to the event, the event itself, and a suitable post-event period to capture the lingering sentiments and discussions.

### 2.2 Data Collection Methods
When it comes to collecting data from X (formerly Twitter), the official method is to use the X API through a developer account. The X API provides a structured and reliable way to access and retrieve data from the platform programmatically. However, using the official X API comes with certain limitations and costs. In our case, the high cost of $100 per month for API access poses a significant challenge, especially for a research project with limited resources. To overcome this limitation, we have decided to explore an alternative approach using the twscrape library in Python. twscrape is an open-source library that provides a simple and efficient way to scrape tweets without the need for an API key. By leveraging twscrape, we can collect a substantial amount of tweet data related to the Saudi Horse Cup while avoiding the high costs associated with the official X API.
Justifications for using twscrape:

    1. Cost-effective: twscrape allows us to collect tweet data without incurring the significant monthly costs associated with the official X API. This is particularly beneficial for research projects with limited budgets.
    2. Simplified data collection: twscrape provides a straightforward and intuitive interface for scraping tweets. It abstracts away the complexities of authentication and API requests, making the data collection process more accessible and efficient.
    3. Flexibility: twscrape offers flexibility in terms of the data we can collect. It allows us to search for tweets based on keywords, hashtags, and time periods, enabling us to gather relevant data specific to the Saudi Horse Cup event.
    4. Community-driven: twscrape is an open-source library maintained by a community of developers. This means that it benefits from regular updates, bug fixes, and contributions from the community, ensuring its reliability and compatibility with the latest changes in the X platform.
To collect the required data using twscrape, we will follow these steps:

    1. Installation: We will install the twscrape library in our Python environment using pip, the package installer for Python.
    2. Search Functionality: twscrape provides a search functionality that allows us to retrieve tweets based on specific keywords, hashtags, and time periods. We will use this functionality to search for tweets containing relevant keywords and hashtags associated with the Saudi Horse Cup event.
    3. Data Extraction: Once we have retrieved the relevant tweets using twscrape, we will extract the necessary information from each tweet, including the text content, timestamp, user details (if available), and any other relevant metadata. twscrape provides methods to access and extract this information from the retrieved tweets.
    4. Data Cleaning and Preprocessing: After extracting the raw data from the tweets, we will perform data cleaning and preprocessing steps to ensure the quality and consistency of the dataset. This may involve removing duplicates, handling missing values, normalizing text, and applying text preprocessing techniques such as tokenization, lowercase conversion, and removing special characters.
    5. Data Storage: The cleaned and preprocessed data will be stored in a structured format, such as CSV (Comma-Separated Values). 


By utilizing the twscrape library and following best practices for data collection, cleaning, and storage, we will gather a comprehensive dataset of tweets related to the Saudi Horse Cup. This dataset will serve as the foundation for the subsequent stages of data analysis, visualization, and sentiment classification. It's important to note that while using twscrape provides a cost-effective and efficient alternative to the official X API, it may come with certain limitations, such as rate limits and the ability to retrieve historical data. However, for the purposes of our research project and given the financial constraints, twscrape presents a viable and practical solution for collecting the necessary tweet data. Throughout the data collection process using twscrape, we will adhere to X's terms of service, developer guidelines, and any applicable legal and ethical considerations. We will also implement measures to handle data privacy and protect user anonymity, such as anonymizing user identities and handling personal information in compliance with relevant regulations.

### 2.3 Data Sampling Strategy

Given the potentially large volume of tweets related to the Saudi Horse Cup event, it is essential to employ an appropriate sampling strategy to ensure a representative and manageable dataset for analysis. In this study, we will adopt a combination of keyword-based and temporal sampling techniques.

1. Keyword-based sampling:
   - We will identify a comprehensive set of relevant keywords and hashtags associated with the Saudi Horse Cup event. These keywords and hashtags will be derived from the event's official promotions, media coverage, and popular user-generated content.
   - The keywords and hashtags will be used to filter and retrieve relevant tweets from the X platform using the twscrape library's search functionality.
   - Examples of potential keywords and hashtags include "Saudi Horse Cup," "#SaudiHorseCup," "#SaudiCup" and variations of these terms in different languages.

2. Temporal sampling:
   - To capture the dynamic nature of the event and the evolving sentiments surrounding it, we will collect tweets within a specified time window.
   - The time window will encompass the period leading up to the event, the event itself, and a suitable period after the event to capture lingering discussions and reactions.
   - The exact start and end dates of the time window will be determined based on the official schedule of the Saudi Horse Cup and an analysis of relevant social media activity.

By combining keyword-based and temporal sampling, we aim to gather a comprehensive dataset that accurately represents the global sentiment towards the Saudi Horse Cup event. This approach ensures that we capture relevant tweets from various geographical regions and time periods, providing a robust foundation for our sentiment analysis and geographical analysis.

It is important to note that the sampling strategy may need to be adjusted or refined during the data collection process to address any unforeseen challenges or to incorporate emerging trends or relevant keywords. Additionally, we will monitor the data collection process and periodically evaluate the representativeness of the collected dataset to ensure its suitability for our analysis objectives.

### 2.4 Ethical Considerations

When conducting research involving social media data, it is crucial to consider ethical implications and ensure that the data collection and analysis processes adhere to ethical principles and guidelines. In this study, we will prioritize the following ethical considerations:

1. **User privacy and anonymity**:
   - We will take measures to protect the privacy and anonymity of the individuals whose tweets are included in our dataset.
   - All personal identifiable information, such as usernames, names, and profile pictures, will be removed or anonymized before data analysis or sharing.
   - We will not attempt to identify or contact individual users based on their tweets.

2. **Informed consent**:
   - While it is not feasible to obtain explicit consent from each user whose tweet is included in our dataset, we will ensure that our data collection process complies with the terms of service and data policies of the X platform.
   - We will provide transparency regarding our research objectives and data collection methods, ensuring that the information is publicly available and accessible.

3. **Data security and storage**:
   - The collected data will be stored securely, with access restricted to authorized researchers involved in the project.
   - We will implement appropriate data encryption and access control measures to prevent unauthorized access or misuse of the data.
   - The data will be retained only for the duration necessary for the research project and will be securely deleted or anonymized after the project's completion.

4. **Responsible data analysis and reporting**:
   - We will strive to maintain objectivity and impartiality in our data analysis and interpretation, avoiding biases or misrepresentations.
   - The findings of our study will be reported accurately and transparently, acknowledging any limitations or potential biases in the data or methodology.
   - We will refrain from making harmful or defamatory claims based on our analysis.

5. **Compliance with regulations and guidelines**:
   - We will ensure compliance with relevant regulations and guidelines concerning data privacy, research ethics, and the responsible use of social media data.
   - This may include obtaining necessary approvals or clearances from institutional review boards or relevant authorities, if required.

By prioritizing ethical considerations throughout the data collection and analysis processes, we aim to conduct our research in a responsible and transparent manner, while minimizing potential risks and ensuring the protection of user privacy and rights. Ethical practices are essential for maintaining the integrity and credibility of our research, as well as fostering public trust in the responsible use of social media data for academic.

## References