
**Warnings and Cautions:**
- Emphasize the critical importance of avoiding plagiarism and ensuring the originality of the content generated by the AI.

I would like to request a write of Chapter 4 with proper references. Specifically, I need the following:

- Compile a comprehensive list of all sources cited in the thesis, formatted according to IEEE guidelines. Ensure:
  - All in-text citations are included in the reference list.
  - No references are listed that were not cited in the text.
  - Correct and consistent formatting for each reference type (journal articles, books, websites, etc.).
  - References should be listed with numbers [26], [27], etc and started number from [26].
  - When writing the chapter, reference numbers should be included in the text like [26], [27].
  - Put your final answer in the md file

Please ensure the highest level of accuracy and adherence to IEEE formatting standards.



### Chapter 4: Sentiment Analysis ...................................... 
   4.1 Sentiment Analysis Overview ................................. 
   4.2 Model Selection ............................................. 
   4.3 Sentiment Analysis Implementation ...........................
   4.4 Sentiment Analysis Results and Visualization ................ 


. Model training and evaluation:
   - Train the sentiment analysis model on the  Sentiment140 dataset with 1.6 million tweets (sentiment140-dataset)
   - Save the trained model locally
   - Evaluate the model on a test dataset
   - Calculate and report accuracy, precision, recall, and F1 score

. Sentiment prediction on Saudi Horse Cup tweets:
   - Load the trained model
   - Predict sentiment for the collected Saudi Horse Cup tweets
   - Add sentiment predictions to the dataset

Note:
- add image. Process used to prepare and build the model classification used in this study.
- add image in 4.4.1 Sentiment Distribution Pie Chart ![Sentiment Distribution Pie Chart](images/sentiment_distribution.png "Sentiment Distribution Pie Chart")
- add write eqution accuracy, precision, recall, and F1 score
-You can add explanatory tables

this is my code can help u write chapter 4:
"""# **Sentiment Analysis**"""

!wget https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip
!unzip trainingandtestdata.zip

class DataLoader():

    def import_tweets(self, path, cols=[0, 5]):
        self.tweets_df = pd.read_csv(path, usecols=cols, names=["label", "text"], encoding='latin-1')
        self.num_tweets = self.tweets_df.shape[0]

        self.tweets_df["text"] = self.tweets_df["text"].astype(str)
        self.tweets_df["label"] = self.tweets_df["label"].astype(str)

        return self.tweets_df

    def split_tweets(self, train_size, test_size):
        self.tweets_train, self.tweets_test = train_test_split(self.tweets_df, train_size=train_size, test_size=test_size)
        return self.tweets_train, self.tweets_test

class TwitterSentimentClassifier():

    def __init__(self, model_name='Twitter/twhin-bert-base', num_labels=2, label2int={"0":0, "4":1}, train_size=100000, test_size=10000):
        self.model_name = model_name
        self.num_labels = num_labels
        self.train_size = train_size
        self.test_size = test_size
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.label_to_int = label2int
        self.metric_accuracy = evaluate.load("accuracy")
        self.metric_precision = evaluate.load("precision")
        self.metric_recall = evaluate.load("recall")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    def tokenize_function(self, batch):
        tokenized_batch = self.tokenizer(batch["text"], padding='max_length', truncation=True, max_length=140)
        tokenized_batch["label"] = [self.label_to_int.get(label, None) for label in batch["label"]]
        return {k: v for k, v in tokenized_batch.items() if k != "label" or v is not None}

    def import_tweets(self, path):
        dl = DataLoader()
        dl.import_tweets(path)
        self.train, self.test = dl.split_tweets(self.train_size, self.test_size)

        self.train = Dataset.from_pandas(self.train)
        self.test = Dataset.from_pandas(self.test)

        self.train_dataset = self.train.map(self.tokenize_function, batched=True)
        self.test_dataset = self.test.map(self.tokenize_function, batched=True)

    def get_metrics(self, predictions, labels):
        accuracy = self.metric_accuracy.compute(predictions=predictions, references=labels)["accuracy"]
        precision = self.metric_precision.compute(predictions=predictions, references=labels)["precision"]
        recall = self.metric_recall.compute(predictions=predictions, references=labels)["recall"]
        f1_score = 2 * (precision * recall) / (precision + recall)

        return {"accuracy": accuracy,
                "precision": precision,
                "recall": recall,
                "f1": f1_score}

    def compute_metrics(self, eval_pred):
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        return self.get_metrics(predictions, labels)

    def train_model(self):
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.num_labels)
        self.model.to(self.device)
        self.training_args = TrainingArguments(
            report_to="none",
            output_dir="training_arguments",
            save_strategy="no",
            evaluation_strategy="epoch",
            per_device_train_batch_size=32,
            per_device_eval_batch_size=32,
            learning_rate=3e-5,
            weight_decay=0.01,
            num_train_epochs=3,
        )

        self.trainer = Trainer(
            model=self.model,
            args=self.training_args,
            train_dataset=self.train_dataset,
            eval_dataset=self.test_dataset,
            compute_metrics=self.compute_metrics,
        )

        self.trainer.train()

    def save_model_local(self, path):
        self.trainer.save_model(path)

    def save_model_cloud(self):
        raise NotImplementedError("not currently implemented")

    def load_saved_model(self, path):
        self.model = AutoModelForSequenceClassification.from_pretrained(path, num_labels=self.num_labels)
        self.model.to(self.device)
        self.pipe = TextClassificationPipeline(model=self.model, tokenizer=self.tokenizer, device=0 if self.device.type == "cuda" else -1)

    def get_scores(self, text):
        return self.pipe(text)

    def predict_dataset(self, dataset_path, batch_size=32):
        # Load the dataset
        df = pd.read_csv(dataset_path)

        # Ensure there's a 'text' column
        if 'text' not in df.columns:
            raise ValueError("The dataset must contain a 'text' column")

        # Make predictions in batches
        predictions = []
        for i in tqdm(range(0, len(df), batch_size), desc="Predicting"):
            batch = df['text'][i:i+batch_size].tolist()
            batch_predictions = self.predict(batch)
            predictions.extend(batch_predictions)

        # Add predictions to the dataframe
        df['predicted_sentiment'] = predictions

        # Map numeric predictions back to labels
        label_map = {0: "Negative", 1: "Positive"}
        df['predicted_sentiment_label'] = df['predicted_sentiment'].map(label_map)

        return df

    def predict(self, text):
        if isinstance(text, str):
            text = [text]

        inputs = self.tokenizer(text, truncation=True, padding='max_length', max_length=140, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=-1)

        return predictions.cpu().numpy().tolist()

    def evaluate_model(self, path, cols=[0, 5]):
        dl = DataLoader()
        dl.import_tweets(path, cols=cols)

        # Filter out rows with labels not in label_to_int
        dl.tweets_df = dl.tweets_df[dl.tweets_df['label'].isin(self.label_to_int.keys())]

        self.eval = Dataset.from_pandas(dl.tweets_df)
        self.eval_dataset = self.eval.map(self.tokenize_function, batched=True)

        predictions = np.array(self.predict(self.eval_dataset["text"]))
        labels = np.array(self.eval_dataset["label"])

        return self.get_metrics(predictions, labels)

ts = TwitterSentimentClassifier()

dataFile = 'training.1600000.processed.noemoticon.csv'


ts.import_tweets(dataFile)

ts.train_model()
result train model
Epoch	Training Loss	Validation Loss	Accuracy	Precision	Recall	F1
1	0.352200	0.325347	0.860200	0.871440	0.848317	0.859723
2	0.267600	0.355485	0.861100	0.875796	0.844752	0.859994
3	0.164500	0.421014	0.858700	0.867003	0.850693	0.858771

ts.save_model_local("twitter-sentiment")

ts.load_saved_model("twitter-sentiment")

ts.evaluate_model("testdata.manual.2009.06.14.csv")
# result {'accuracy': 0.8495821727019499,
 'precision': 0.8168316831683168,
 'recall': 0.9065934065934066,
 'f1': 0.859375}

results_df = ts.predict_dataset("dataset.csv")

#result 14% negitivw

#  save the results
results_df.to_csv("predictions_output.csv", index=False)

# Pie chart of sentiment distribution
sentiment_counts = results_df['predicted_sentiment_label'].value_counts()
plt.figure(figsize=(8, 8))
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%')
plt.title('Sentiment Distribution')
plt.show()


